## 现状
****
训练效率的瓶颈主要在以下几个方面
1. 硬件限制：cpu为 2017年的一代xeon
   * 无神经网络相关的定制化特征，如低精度等
2. 架构限制：ps架构分布式通信性能低，随模型规模的增长，衰减厉害
   * 以汇川CVR为例，通信耗时已超 50%，可以转向高性能 GPC架构
3. 框架：训练框架的不合理或者可提升的地方，如节点参数均衡分配、节点训练长尾、计算图优化等
4. 模型规模：尤其是 ev，几十亿近上百亿的规模使得ps架构达到瓶颈

针对第3，引入DeepRec框架，基于已有的一些底层效率工具，二次开发以适配分布式推荐模型。
针对第4点，引入特征增强/交互模块，剔除人工组合特征，即在不降低模型效果的前提下，极致压缩模型规模，降低通信负载，间接达到训练效率提升的目的

## DeepRec框架
### EV exporter接口
**设计目的**
节省存储计算资源，提高模型时效性

**机制**
deeprec重写了kv_variable_ops算子，支持特征meta信息的统计，包括
1. var-keys:特征的id
2. var-values:特征的embedding
3. var-freqs:特征被查询的次数
4. var-versions:特征最近一次被更新的 global step

**收益**
对比训练后过滤:
1. 无论多么激进的过滤阈值，确保了离线在线模型效果的一致性
2. 节省大量的离线特征统计相关的存储资源（50%），部分sql计算资源
4. 高过滤阈值为后续模型的无限训练提供基础
### 特征增量训练
**设计目的**
避免周级模型的回刷，无限长训练样本带来的效果增益

**机制**
旧模型参数自动迁移到新模型，重复利用；新增参数随机初始化

**特点&收益**
1. 新模型续跑30天可回收 70%-80%的auc增益
2. 回收周模型的训练资源（ctr上大概50%，cvr未统计）
### WorkQueue
**目的**
起因是我们发现cpu混布集群上，各节点训练时随着数据量的增大，及集群水位的提升，存在严重的长尾问题

**机制**
WorkQueueHandleOp 支持odps样本级分片，通过维护大量的细粒度任务队列，动态分配work任务，避免长尾

**收益**
训练效率预计提升 2x，落地调研中
## 特征增强/交互算法
### Before 2020
****
**(IEEE '16)PNN**
内外积提取特征二阶交互
* IPNN, 特征内积，学习向量级交互
* OPNN, 特征外积后求和，学习bit位级交互
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722329402907-da341967-d7e1-406d-99e0-d2704022bcbb.png) 

**(IJCAI '17)DeepFM**
* 提取一阶及二阶特征
* 以wide deep架构为基础，利用FM代替wide部分，学习 pairwise 向量级交互
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722336672217-e2a4d1a3-5c59-4094-8a77-0b1f834ff784.png) 
* FM结构
$$
y_{FM} = \langle w, x \rangle + \sum_{j_1=1}^{d} \sum_{j_2=j_1+1}^{d} \langle V_{i}, V_{j} \rangle x_{j_1} \cdot x_{j_2}
$$

**(KDD '17)DCN**
* 开始提取二阶以上的高阶特征，但属于bit级别交互
* 交互结构
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722336482524-c4e702d8-50ec-4e88-b47c-beda9805b619.png)
* 整体结构
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722336516360-90f62d3b-d72b-4ea5-aa5d-22a8f981ff5b.png) 

**(KDD '18)xDeepFM**
* 包含一阶及高阶FM
* 改进为向量级交互
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722393297033-b94e2731-3fd0-4af0-9997-f581d27adb76.png) 
* 交互及预估结构
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722393269812-a0e3d80b-3f70-45c9-a423-be72c9d59189.png) 

**(RecSys '19)FiBiNET**
* 首次使用上下文感知的特征增强模块，采用senet提取增强特征
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722326969625-3bc2da79-4055-479e-8906-e5aa778f3a3e.png)
* 双向交互
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722394301549-175f551a-ef19-4f65-95eb-ef77262fa11c.png) 

### (KDD ‘20) xDeepInt
****
提出多项式交互层(PIN)，以及一个模型优化方法G-FTRL和FTRL
**PIN**
* 公式及图解
  $$
X_{l} = X_{l-1} \circ (\mathbf{W}_{l-1} \cdot \mathbf{X}_0) + X_{l-1}
$$
  ![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1721209244097-8dd6bc6c-4606-42a7-b057-6360d78a06bd.png)

*  子空间交互机制(bit 交互)
特征向量切分为n个子空间，拼接到第一维
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1721209361637-86ab23bb-ba55-4bfb-bb9a-1725ccaf33f2.png) 


**优化方法**
* 使用 The Group Lasso 优化ev，提升效果并进一步压缩模型
  ![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1721209678831-48a75c4c-451a-465f-b179-b2c5236007a0.png) 

### (WWW '21) DCN-v2、DCN-mix
****
**DCV-v2** 
* 基于DCN的增强版网络结构,引入更多参数，即参数矩阵代替参数向量
  ![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1721034082830-f0b8a82f-8ad2-4bb0-b31e-5541fd091587.png)

**DCN-mix**
* 考虑模型性能与效果的中间版本，引入两个小矩阵代替低秩矩阵
$$
x_{l+1} = x_0 \odot \left( U_l \left( V_l^\top x_i \right) + b_l \right) + x_i
$$
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722395579259-dbe0e14f-b182-49cf-a43b-98da5c7ceca2.png) 
* 引入 moe，多个cross layer共同决策
  $$
x_{l+1} = \sum_{i=1}^{K} G_i(x_l) E_i(x_l) + x_l
$$

$$
E_i(x_l) = x_0 \odot \left( U_i^l \left( V_i^l x_l \right) + b_l \right)
$$
* 同时进一步增强交互时的非线性能力
$$
E_i(x_l) = x_0 \odot \left( U_i^l \cdot g\left( C_i^l \cdot g(V_i^{l \top} x_l) \right) + b_l \right)
$$

### (WSDM ‘22) Co-Action Network  
****
* 另辟蹊径，使用样本级交互参数
两个交互的特征，定义为 feed 和 induction，分别作为 CAN 网络的输入与参数，计算交互结果向量 

**图解**
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1721183701045-fa5994e3-bc58-426b-b9d3-51a74f59281d.png) 

**多阶增量**
* feed做高次方运算，得到多个feed，与induction交互产生多个交互结果求和，作为最终的多阶组合表达  

**三层独立** 
* 定义独立：特征ev与feed及induction参数相互独立定义
* 组合独立：一个特征与n个特征进行组合时，feed与induction定义n套独立参数
* 多阶独立：feed产出n个高阶feed时，induction匹配n套独立参数

**经验参数**
* Amazon dataset测试：CAN网络两层，feed 3阶输入，取前两层独立
* 效果优于 PNN
* 带来线上优化问题

### (SIGIR '22) FRNet ###
* 具有上下文意识的增强网络，整体结构如下
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722396273297-71d81473-7824-4e45-a1bb-35aff96c3062.png) 
* CIE结构的作用
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722340281742-7f8b4c93-3a7c-4345-ad68-656fc0d6e44b.png)
* 上下文的特征表征能力
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722340321298-ec0c7d86-56c4-4935-8721-fb8b06a24024.png)

### (arxiv '23) DyInt ###
****
xDeepInt升级版，引入gate网络级矩阵分解
包含三种网络，DynInt-DA、DynInt-DGP、DynInt-DWP，后两者引入参数矩阵分解，减少参数量
**DynInt-DA**
* 交互公式如下，引入gate网络作为动态参数
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722400696421-f5753ea7-4627-42e7-80d3-a7b9d9de5c04.png) 
$$
X_{l} = \left( X_{l-1} \circ \left( \mathbf{W}_{l-1} \cdot \mathbf{X}_0 \right) \right) \circ \mathbf{G}_{l-1}^{(i)} + X_{l-1}
$$
1. gate网络取两层DNN，输出 Sigmoid(𝑥) ∗ 2.0
2. gate网络取消梯度回传

**DyInt-DP**
$$
X_t = X_{t-1} \circ \left( \left( G^{(i)}_{t-1} \circ W_{t-1} \cdot X_0 \right) \right) + X_{t-1}
$$
**DynInt-DGP**
$$
W_{l-1}^{(i)} = U_{l-1} \cdot \Sigma_{l-1}^{(i)} \cdot V_{l-1}^{T}
$$
  
### (arxiv '23) Gated Deep Cross Network ###
****
对比 DCN-v2，细化了gate网络，不用于组合专家，用于筛选特征
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722400183246-b04f6d3e-6a9a-495d-8e2d-5c1183224558.png) 

**交叉公式**
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722400201360-9a0eaf4d-87e2-4adf-a627-cc6495a999b6.png) 
$$
c_{l+1} = c_0 \odot \left( W_i^{(c)} \times c_l + b_i \right) \odot \sigma \left( W_i^{(g)} \times c_i \right) + c_i
$$

**维度优化 FDO**
普遍方法是计算特征数的 1/4 次方作为维度k，新方法如下
1. 使用固定维度训练一个模型
2. PCA对每个特征计算特征值集合，从大到小排序
3. 根据前k个特征的信息占比，决定新的维度 k

### (arxiv '23) Feature Refinement Modules ###
* 增强和交互的组合
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722340855247-4239e740-a6a7-49d1-9837-173e8ac68057.png)

### (SIGIR '23) Euler Net ###
* 任意阶特征交互
* 复数空间输入
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722932860204-8f5c9c4c-f5da-4dfd-b018-b64b3e74248e.png) 

### (KDD '24) RFM ###
* 引入上下文信息，不同样本在同一域内有不同阶数
![undefined](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/221560/1722932920075-03252a69-0267-4a87-888e-08b5013b3a10.png) 


## BatchLLM
项目地址：https://code.alibaba-inc.com/com-model/BatchLLM











